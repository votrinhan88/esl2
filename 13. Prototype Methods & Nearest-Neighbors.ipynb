{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Literal, Optional\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from typing import Literal, Sequence\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'figure.titlesize': 12,\n",
    "    'axes.titlesize':   10,\n",
    "    'axes.labelsize':   10,\n",
    "    'font.size':        8,\n",
    "    'xtick.labelsize':  8,\n",
    "    'ytick.labelsize':  8,\n",
    "    'legend.fontsize':  8,\n",
    "    'lines.linewidth':  1,\n",
    "})\n",
    "\n",
    "COLORS = ['red', 'blue', 'green', 'orange', 'purple',\n",
    "          'brown', 'pink', 'gray', 'olive', 'cyan',\n",
    "          'tab:red', 'tab:blue', 'tab:green', 'tab:orange', 'tab:purple',\n",
    "          'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prototype Methods\n",
    "    + K-means Clustering\n",
    "    + Learning Vector Quantization\n",
    "    + Gaussian Mixtures\n",
    "2. k-Nearest-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(nn.Module):\n",
    "    def __init__(self, X_train:Tensor):\n",
    "        super(Normalizer, self).__init__()\n",
    "        \n",
    "        self.mean = X_train.mean(dim=0)\n",
    "        self.std = X_train.std(dim=0)\n",
    "\n",
    "    def forward(self, input:Tensor) -> Tensor:\n",
    "        return self.normalize(input=input)\n",
    "\n",
    "    def normalize(self, input:Tensor) -> Tensor:\n",
    "        return (input - self.mean)/self.std\n",
    "\n",
    "    def unnormalize(self, input:Tensor) -> Tensor:\n",
    "        return input*self.std + self.mean\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        params = {\n",
    "            'mean':self.mean,\n",
    "            'std': self.std,\n",
    "        }\n",
    "        return ', '.join([f'{k}={v}' for k, v in params.items() if v is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansClustering(nn.Module):\n",
    "    def __init__(self, num_centroids:int):\n",
    "        super(KMeansClustering, self).__init__()\n",
    "        self.num_centroids = num_centroids\n",
    "        \n",
    "    def forward(self, input:Tensor, with_distance:bool=False):\n",
    "        distance = torch.zeros([input.size()[0], self.num_centroids])\n",
    "        for k in torch.arange(self.num_centroids):\n",
    "            distance[:, k] = torch.sqrt(torch.sum((self.centroids[k, :] - input)**2, dim=1))\n",
    "        yhat = distance.argmin(dim=1, keepdim=True)\n",
    "        \n",
    "        if with_distance == False:\n",
    "            return yhat\n",
    "        else:\n",
    "            return yhat, distance\n",
    "\n",
    "    def backward(self, input:Tensor, pred:Tensor):\n",
    "        for k in torch.arange(self.num_centroids):\n",
    "            self.centroids[k, :] = torch.mean(input[pred.squeeze()==k, :], dim = 0)\n",
    "            \n",
    "    def fit(self, X_train:Tensor, centroids_init:Optional[Tensor]=None, with_logs:bool=False) -> Tensor:\n",
    "        if centroids_init is None:\n",
    "            rand_idx = torch.randperm(n=X_train.shape[0])[0:self.num_centroids]\n",
    "            self.centroids = X_train[rand_idx]\n",
    "        else:\n",
    "            self.centroids = centroids_init\n",
    "        \n",
    "        centroids_log = torch.unsqueeze(self.centroids.clone(), dim=0)\n",
    "        converge = False\n",
    "        while not converge:\n",
    "            # Fix centroids, update labels\n",
    "            yhat = self.forward(input=X_train)\n",
    "            # Fix labels, update centroids\n",
    "            self.backward(input=X_train, pred=yhat)\n",
    "            # Log centroids position\n",
    "            centroids_log = torch.cat([centroids_log, self.centroids.unsqueeze(dim=0)], dim=0)\n",
    "            # Check for stopping condition: when centroids stop moving\n",
    "            converge = (centroids_log[-1] == centroids_log[-2]).all()\n",
    "\n",
    "        if with_logs == False:\n",
    "            return self.centroids.clone()\n",
    "        else:\n",
    "            return self.centroids.clone(), centroids_log.clone()\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        params = {\n",
    "            'num_centroids':self.num_centroids,\n",
    "        }\n",
    "        return ', '.join([f'{k}={v}' for k, v in params.items() if v is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    from utils_data import get_clusters_2D\n",
    "\n",
    "    NUM_CLUSTERS = 4\n",
    "    NUM_CENTROIDS = 4\n",
    "    PLOT_STEP = 0.01\n",
    "\n",
    "    X_train = get_clusters_2D(num_clusters=NUM_CLUSTERS, radius=1.5, sigma_diag=0.1)[0]\n",
    "    normalizer = Normalizer(X_train=X_train)\n",
    "    \n",
    "    # Train\n",
    "    h = KMeansClustering(num_centroids=NUM_CENTROIDS)\n",
    "    centroids, centroids_log = h.fit(X_train=normalizer(X_train), with_logs=True)\n",
    "    centroids = normalizer.unnormalize(centroids)\n",
    "    centroids_log = normalizer.unnormalize(centroids_log)\n",
    "    yhat = h(X_train)\n",
    "\n",
    "    # Plot all centroids and examples \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(h)\n",
    "    for k in torch.arange(h.num_centroids):\n",
    "        # Centroids' path\n",
    "        ax.plot(centroids_log[:, k, 0], centroids_log[:, k, 1],\n",
    "                color=COLORS[k], linestyle='dashed')\n",
    "        ax.scatter(centroids_log[0:-1, k, 0], centroids_log[0:-1, k, 1],\n",
    "                color=COLORS[k], marker='o', s=15)\n",
    "        ax.scatter(centroids_log[-1, k, 0], centroids_log[-1, k, 1],\n",
    "                color=COLORS[k], marker='o', s=70)\n",
    "\n",
    "        # Training data\n",
    "        ax.scatter(X_train[yhat.squeeze()==k, 0], X_train[yhat.squeeze()==k, 1],\n",
    "                color=COLORS[k], alpha=0.7, s=2, zorder=100)\n",
    "\n",
    "    # Decision boundary\n",
    "    ptp_X = X_train.max(dim = 0)[0] - X_train.min(dim = 0)[0]\n",
    "    plot_x1 = torch.arange(X_train[:, 0].min() - 0.2*ptp_X[0], X_train[:, 0].max() + 0.2*ptp_X[1], PLOT_STEP)\n",
    "    plot_x2 = torch.arange(X_train[:, 1].min() - 0.2*ptp_X[0], X_train[:, 1].max() + 0.2*ptp_X[1], PLOT_STEP)\n",
    "    x1, x2 = torch.meshgrid([plot_x1 - PLOT_STEP/2, plot_x2 - PLOT_STEP/2])\n",
    "    x = torch.cat([x1.flatten().unsqueeze(dim=1), x2.flatten().unsqueeze(dim=1)], dim=1)\n",
    "    plot_yhat = h.forward(x).reshape([plot_x1.size()[0], plot_x2.size()[0]])\n",
    "\n",
    "    ax.pcolormesh(x1, x2, plot_yhat,\n",
    "                  cmap=ListedColormap(COLORS[0:h.num_centroids]), alpha=0.2, shading='auto')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansClassifier(nn.Module):\n",
    "    def __init__(self, num_centroids_per_class:int):\n",
    "        super(KMeansClassifier, self).__init__()\n",
    "        self.num_classes = -1\n",
    "        self.num_centroids_per_class = num_centroids_per_class\n",
    "    \n",
    "    def forward(self, input:Tensor, with_distance:bool=False):\n",
    "        distance = torch.zeros([input.shape[0], self.num_classes, self.num_centroids_per_class])\n",
    "        for k in range(self.num_classes):\n",
    "            distance[:, k, :] = self.clusterers[k](input=input, with_distance=True)[1]\n",
    "        \n",
    "        yhat = distance.min(dim=2)[0].argmin(dim=1)\n",
    "        \n",
    "        if with_distance == False:\n",
    "            return yhat\n",
    "        else:\n",
    "            return yhat, distance\n",
    "        \n",
    "    def fit(self,\n",
    "        X_train:Tensor,\n",
    "        y_train:Tensor,\n",
    "        with_logs:bool=False\n",
    "    ) -> Tensor:\n",
    "        self.num_classes = y_train.unique().shape[0]\n",
    "        self.clusterers = [KMeansClustering(num_centroids=self.num_centroids_per_class) for k in range(self.num_classes)]\n",
    "        self.idx_k = [(y_train.squeeze(dim=1) == k).nonzero().squeeze(dim=1) for k in range(self.num_classes)]\n",
    "        \n",
    "        centroids = [None]*self.num_classes\n",
    "        centroids_log = [None]*self.num_classes\n",
    "        for k in range(self.num_classes):\n",
    "            fit_outputs = self.clusterers[k].fit(\n",
    "                X_train=X_train[self.idx_k[k]],\n",
    "                with_logs=with_logs,\n",
    "            )\n",
    "            \n",
    "            if with_logs == False:\n",
    "                centroids[k] = fit_outputs\n",
    "            else:\n",
    "                centroids[k] = fit_outputs[0]\n",
    "                centroids_log[k] = fit_outputs[1].clone()\n",
    "        \n",
    "        self.centroids = torch.stack(tensors=centroids, dim=0)\n",
    "        \n",
    "        if with_logs == False:\n",
    "            return self.centroids.clone()\n",
    "        else:\n",
    "            return self.centroids.clone(), centroids_log\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        params = {\n",
    "            'num_classes':             self.num_classes,\n",
    "            'num_centroids_per_class': self.num_centroids_per_class,\n",
    "        }\n",
    "        return ', '.join([f'{k}={v}' for k, v in params.items() if v is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    from utils_data import get_clusters_2D\n",
    "\n",
    "    NUM_CLUSTERS = 4\n",
    "    NUM_CLASSES = 4\n",
    "    NUM_CENTROIDS_PER_CLASS = 3\n",
    "    PLOT_STEP = 0.01\n",
    "\n",
    "    X_train, y_train = get_clusters_2D(num_clusters=NUM_CLUSTERS, radius=1, sigma_diag=0.2)\n",
    "    normalizer = Normalizer(X_train=X_train)\n",
    "    \n",
    "    # Train\n",
    "    h = KMeansClassifier(num_centroids_per_class=NUM_CENTROIDS_PER_CLASS)\n",
    "    centroids, centroids_log = h.fit(X_train=normalizer(X_train), y_train=y_train, with_logs=True)\n",
    "    centroids = normalizer.unnormalize(centroids)\n",
    "    centroids_log = [normalizer.unnormalize(cl) for cl in centroids_log]\n",
    "    yhat = h(X_train)\n",
    "\n",
    "    # Plot all centroids and examples \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(h)\n",
    "    \n",
    "    for k in torch.arange(h.num_classes):\n",
    "        for j in torch.arange(h.num_centroids_per_class):\n",
    "            # Centroids' path\n",
    "            ax.plot(centroids_log[k][:, j, 0], centroids_log[k][:, j, 1],\n",
    "                    color=COLORS[k], linestyle='dashed')\n",
    "            ax.scatter(centroids_log[k][0:-1, j, 0], centroids_log[k][0:-1, j, 1],\n",
    "                    color=COLORS[k], marker='o', s=15)\n",
    "            ax.scatter(centroids_log[k][-1, j, 0], centroids_log[k][-1, j, 1],\n",
    "                    color=COLORS[k], marker='o', s=70)\n",
    "\n",
    "        # Training data\n",
    "        ax.scatter(X_train[y_train.squeeze()==k, 0], X_train[y_train.squeeze()==k, 1],\n",
    "                color=COLORS[k], alpha=0.7, s=2, zorder=100)\n",
    "\n",
    "    # Decision boundary\n",
    "    ptp_X = X_train.max(dim = 0)[0] - X_train.min(dim = 0)[0]\n",
    "    plot_x1 = torch.arange(X_train[:, 0].min() - 0.2*ptp_X[0], X_train[:, 0].max() + 0.2*ptp_X[1], PLOT_STEP)\n",
    "    plot_x2 = torch.arange(X_train[:, 1].min() - 0.2*ptp_X[0], X_train[:, 1].max() + 0.2*ptp_X[1], PLOT_STEP)\n",
    "    x1, x2 = torch.meshgrid([plot_x1 - PLOT_STEP/2, plot_x2 - PLOT_STEP/2])\n",
    "    x = torch.cat([x1.flatten().unsqueeze(dim = 1), x2.flatten().unsqueeze(dim = 1)], dim = 1)\n",
    "    plot_yhat = h.forward(x).reshape([plot_x1.size()[0], plot_x2.size()[0]])\n",
    "\n",
    "    ax.pcolormesh(x1, x2, plot_yhat,\n",
    "                  cmap=ListedColormap(COLORS[0:h.num_classes]), alpha=0.2, shading='auto')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningVectorQuantization(nn.Module):\n",
    "    def __init__(self, num_centroids_per_class:int):\n",
    "        super(LearningVectorQuantization, self).__init__()\n",
    "        self.num_centroids_per_class = num_centroids_per_class\n",
    "        self.num_classes = -1\n",
    "    \n",
    "    def forward(self, input:Tensor):\n",
    "        input = input.view(input.shape[0], 1, 1, *input.shape[1:])\n",
    "        distance = (input - self.centroids).norm(p=2, dim=3)\n",
    "        yhat = distance.min(dim=2)[0].argmin(dim=1)\n",
    "        return yhat\n",
    "    \n",
    "    def fit(self, X_train:Tensor, y_train:Tensor, centroids_init:Optional[Tensor]=None, num_iters:Optional[int]=None, lr_init:float=0.1) -> Tensor:\n",
    "        self.num_classes = y_train.unique().shape[0]\n",
    "        self.idx_k = [(y_train.squeeze(dim=1) == k).nonzero().squeeze(dim=1) for k in range(self.num_classes)]\n",
    "        if num_iters is None:\n",
    "            num_iters = X_train.shape[0]\n",
    "        \n",
    "        # 1. Choose R initial prototypes for each class: m1(k), m2(k), . . . , mR(k),\n",
    "        # k = 1, 2, . . . , K, for example, by sampling R training points at random from each class.\n",
    "        if centroids_init is None:\n",
    "            centroids = [None]*self.num_classes\n",
    "            for k in range(self.num_classes):\n",
    "                rand_idx_k = torch.randperm(n=self.idx_k[k].shape[0])[0:self.num_centroids_per_class]\n",
    "                centroids[k] = X_train[self.idx_k[k][rand_idx_k]]\n",
    "            self.centroids = torch.stack(tensors=centroids, dim=0)\n",
    "        else:\n",
    "            self.centroids = centroids_init\n",
    "\n",
    "        # 2. Sample a training point xi randomly (with replacement), and let (j, k)\n",
    "        # index the closest prototype mj(k) to xi.\n",
    "        # 3. Repeat step 2, decreasing the learning rate Ç« with each iteration to wards zero.\n",
    "        for i in range(num_iters):\n",
    "            lr = lr_init*(num_iters-i)/num_iters\n",
    "            \n",
    "            rand_idx = torch.randint(low=0, high=X_train.shape[0], size=[1]).item()\n",
    "            x, y = X_train[rand_idx], y_train[rand_idx]\n",
    "            x = x.view(1, 1, *x.shape)\n",
    "            \n",
    "            distance = (x - self.centroids).norm(p=2, dim=2)\n",
    "            closest_centroid = (distance == distance.min()).nonzero().squeeze(dim=0)\n",
    "            \n",
    "            direction = (x - self.centroids[*closest_centroid] > 0).to(dtype=torch.int)\n",
    "            self.centroids[*closest_centroid] = self.centroids[*closest_centroid] + direction*lr*(x-self.centroids[*closest_centroid])\n",
    "        return self.centroids.clone()\n",
    "            \n",
    "    def extra_repr(self) -> str:\n",
    "        params = {\n",
    "            'num_classes':             self.num_classes,\n",
    "            'num_centroids_per_class': self.num_centroids_per_class,\n",
    "        }\n",
    "        return ', '.join([f'{k}={v}' for k, v in params.items() if v is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    from utils_data import get_clusters_2D\n",
    "\n",
    "    NUM_CLUSTERS = 4\n",
    "    NUM_CLASSES = 4\n",
    "    NUM_CENTROIDS_PER_CLASS = 3\n",
    "    LR_INIT = 0.01\n",
    "    NUM_ITERS = 6000\n",
    "    PLOT_STEP = 0.01\n",
    "\n",
    "    X_train, y_train = get_clusters_2D(num_clusters=NUM_CLUSTERS, radius=1, sigma_diag=0.4)\n",
    "    normalizer = Normalizer(X_train=X_train)\n",
    "    \n",
    "    # Train\n",
    "    h = LearningVectorQuantization(num_centroids_per_class=NUM_CENTROIDS_PER_CLASS)\n",
    "    centroids = h.fit(X_train=normalizer(X_train), y_train=y_train, lr_init=LR_INIT, num_iters=NUM_ITERS)\n",
    "    centroids = normalizer.unnormalize(centroids)\n",
    "    yhat = h(X_train)\n",
    "\n",
    "    # Plot all centroids and examples \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(h)\n",
    "    \n",
    "    for k in torch.arange(h.num_classes):\n",
    "        for j in torch.arange(h.num_centroids_per_class):\n",
    "            ax.scatter(centroids[k, j, 0], centroids[k, j, 1],\n",
    "                    color=COLORS[k], marker='o', s=70)\n",
    "\n",
    "        # Training data\n",
    "        ax.scatter(X_train[y_train.squeeze()==k, 0], X_train[y_train.squeeze()==k, 1],\n",
    "                color=COLORS[k], alpha=0.7, s=2, zorder=100)\n",
    "\n",
    "    # Decision boundary\n",
    "    ptp_X = X_train.max(dim = 0)[0] - X_train.min(dim = 0)[0]\n",
    "    plot_x1 = torch.arange(X_train[:, 0].min() - 0.2*ptp_X[0], X_train[:, 0].max() + 0.2*ptp_X[1], PLOT_STEP)\n",
    "    plot_x2 = torch.arange(X_train[:, 1].min() - 0.2*ptp_X[0], X_train[:, 1].max() + 0.2*ptp_X[1], PLOT_STEP)\n",
    "    x1, x2 = torch.meshgrid([plot_x1 - PLOT_STEP/2, plot_x2 - PLOT_STEP/2])\n",
    "    x = torch.cat([x1.flatten().unsqueeze(dim = 1), x2.flatten().unsqueeze(dim = 1)], dim = 1)\n",
    "    plot_yhat = h(x).reshape([plot_x1.size()[0], plot_x2.size()[0]])\n",
    "\n",
    "    ax.pcolormesh(x1, x2, plot_yhat,\n",
    "                  cmap=ListedColormap(COLORS[0:h.num_classes]), alpha=0.2, shading='auto')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    from utils_data import get_clusters_2D\n",
    "\n",
    "    NUM_CLUSTERS = 4\n",
    "    NUM_CLASSES = 4\n",
    "    NUM_CENTROIDS_PER_CLASS = 3\n",
    "    LR_INIT = 0.01\n",
    "    NUM_ITERS = 6000\n",
    "    PLOT_STEP = 0.01\n",
    "\n",
    "    X_train, y_train = get_clusters_2D(num_clusters=NUM_CLUSTERS, radius=1, sigma_diag=0.4)\n",
    "    normalizer = Normalizer(X_train=X_train)\n",
    "    \n",
    "    # Train\n",
    "    kmeans = KMeansClassifier(num_centroids_per_class=NUM_CENTROIDS_PER_CLASS)\n",
    "    kmeans_centroids, centroids_log = kmeans.fit(X_train=normalizer(X_train), y_train=y_train, with_logs=True)\n",
    "    kmeans_centroids = normalizer.unnormalize(kmeans_centroids)\n",
    "    \n",
    "    lvq = LearningVectorQuantization(num_centroids_per_class=NUM_CENTROIDS_PER_CLASS)\n",
    "    lvq_centroids = lvq.fit(X_train=normalizer(X_train), y_train=y_train, lr_init=LR_INIT, num_iters=NUM_ITERS, centroids_init=normalizer(kmeans_centroids))\n",
    "    lvq_centroids = normalizer.unnormalize(lvq_centroids)\n",
    "    yhat = lvq(X_train)\n",
    "\n",
    "\n",
    "    # Plot all centroids and examples \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=[12, 5], squeeze=False)\n",
    "    ax[0, 0].set_title(kmeans)\n",
    "    \n",
    "    # K-means\n",
    "    for k in torch.arange(kmeans.num_classes):\n",
    "        for j in torch.arange(kmeans.num_centroids_per_class):\n",
    "            # Centroids' path\n",
    "            ax[0, 0].plot(centroids_log[k][:, j, 0], centroids_log[k][:, j, 1],\n",
    "                    color=COLORS[k], linestyle='dashed')\n",
    "            ax[0, 0].scatter(centroids_log[k][0:-1, j, 0], centroids_log[k][0:-1, j, 1],\n",
    "                    color=COLORS[k], marker='o', s=15)\n",
    "            ax[0, 0].scatter(centroids_log[k][-1, j, 0], centroids_log[k][-1, j, 1],\n",
    "                    color=COLORS[k], marker='o', s=70)\n",
    "        # Training data\n",
    "        ax[0, 0].scatter(X_train[y_train.squeeze()==k, 0], X_train[y_train.squeeze()==k, 1],\n",
    "                color=COLORS[k], alpha=0.7, s=2, zorder=100)\n",
    "    # Decision boundary\n",
    "    ptp_X = X_train.max(dim = 0)[0] - X_train.min(dim = 0)[0]\n",
    "    plot_x1 = torch.arange(X_train[:, 0].min() - 0.2*ptp_X[0], X_train[:, 0].max() + 0.2*ptp_X[1], PLOT_STEP)\n",
    "    plot_x2 = torch.arange(X_train[:, 1].min() - 0.2*ptp_X[0], X_train[:, 1].max() + 0.2*ptp_X[1], PLOT_STEP)\n",
    "    x1, x2 = torch.meshgrid([plot_x1 - PLOT_STEP/2, plot_x2 - PLOT_STEP/2])\n",
    "    x = torch.cat([x1.flatten().unsqueeze(dim = 1), x2.flatten().unsqueeze(dim = 1)], dim = 1)\n",
    "    plot_yhat = kmeans.forward(x).reshape([plot_x1.size()[0], plot_x2.size()[0]])\n",
    "\n",
    "    ax[0, 0].pcolormesh(x1, x2, plot_yhat,\n",
    "                  cmap=ListedColormap(COLORS[0:kmeans.num_classes]), alpha=0.2, shading='auto')\n",
    "    \n",
    "    # LVQ\n",
    "    ax[0, 1].set_title(lvq)\n",
    "    for k in torch.arange(lvq.num_classes):\n",
    "        for j in torch.arange(lvq.num_centroids_per_class):\n",
    "            ax[0, 1].scatter(lvq_centroids[k, j, 0], lvq_centroids[k, j, 1],\n",
    "                    color=COLORS[k], marker='o', s=70)\n",
    "        # Training data\n",
    "        ax[0, 1].scatter(X_train[y_train.squeeze()==k, 0], X_train[y_train.squeeze()==k, 1],\n",
    "                color=COLORS[k], alpha=0.7, s=2, zorder=100)\n",
    "\n",
    "    # Decision boundary\n",
    "    ptp_X = X_train.max(dim = 0)[0] - X_train.min(dim = 0)[0]\n",
    "    plot_x1 = torch.arange(X_train[:, 0].min() - 0.2*ptp_X[0], X_train[:, 0].max() + 0.2*ptp_X[1], PLOT_STEP)\n",
    "    plot_x2 = torch.arange(X_train[:, 1].min() - 0.2*ptp_X[0], X_train[:, 1].max() + 0.2*ptp_X[1], PLOT_STEP)\n",
    "    x1, x2 = torch.meshgrid([plot_x1 - PLOT_STEP/2, plot_x2 - PLOT_STEP/2])\n",
    "    x = torch.cat([x1.flatten().unsqueeze(dim = 1), x2.flatten().unsqueeze(dim = 1)], dim = 1)\n",
    "    plot_yhat = lvq(x).reshape([plot_x1.size()[0], plot_x2.size()[0]])\n",
    "\n",
    "    ax[0, 1].pcolormesh(x1, x2, plot_yhat,\n",
    "                  cmap=ListedColormap(COLORS[0:lvq.num_classes]), alpha=0.2, shading='auto')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
